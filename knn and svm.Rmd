---
title: "KNN and SVM"
author: "Yingyao Gong, Yulu He, Zichuan Yu"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r,message=FALSE,warning=FALSE}
library(class)
library(ggplot2)
data <- read.csv("data.csv")
data <- subset(data,select= - c(X,id))
set.seed(123) 

# Split data into training and testing
train_indices <- sample(1:nrow(data), 0.7 * nrow(data)) 
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]

# Initialize vectors to store accuracies
test_accuracy_seq <- rep(0, 10)
train_accuracy_seq <- rep(0, 10)

# Calculate accuracies for different values of K
for (k in 1:10) {
  # Predict using training data
  predicted_train <- knn(train = train_data[,-1], test = train_data[,-1], 
                         cl = train_data$diagnosis, k = k)
  train_accuracy_seq[k] <- mean(predicted_train == train_data$diagnosis)
  
  # Predict using test data
  predicted_test <- knn(train = train_data[,-1], test = test_data[,-1], 
                        cl = train_data$diagnosis, k = k)
  test_accuracy_seq[k] <- mean(predicted_test == test_data$diagnosis)
}

# Create a data frame for plotting
accuracy_data <- data.frame(
  k = 1:10,
  Train_Accuracy = train_accuracy_seq,
  Test_Accuracy = test_accuracy_seq
)

# Plotting with ggplot2
ggplot(accuracy_data, aes(x = k)) +
  geom_line(aes(y = Train_Accuracy, colour = "Training")) +
  geom_line(aes(y = Test_Accuracy, colour = "Testing")) +
  labs(title = "Training and Test Accuracy vs. K",
       x = "Number of Neighbors (K)",
       y = "Accuracy") +
  scale_colour_manual("", 
                      breaks = c("Training", "Testing"),
                      values = c("blue", "red"))

# Output the chosen k = 5 accuracy
chosen_k_accuracy <- test_accuracy_seq[5]
print(paste("Accuracy for k=5:", chosen_k_accuracy))


#predict probabilty
predicted_labels <- knn(train = train_data[, -1], test = test_data[, -1], cl = train_data$diagnosis, k = 5, prob = TRUE)
knn_predicted_probabilities <- attr(predicted_labels, "prob")

# cross validation 10-fold cross validation 
library(class)
set.seed(123)
indices <- sample(1:nrow(data), nrow(data))
folds <- cut(indices, breaks=10, labels=FALSE)
accuracy <- numeric(10)
train_error <- numeric(10)
test_error <- numeric(10)

for(i in 1:10) {
  test_indices <- which(folds == i, arr.ind=TRUE)
  train_indices <- which(folds != i, arr.ind=TRUE)
  
  train_data <- data[train_indices, -1]  
  test_data <- data[test_indices, -1]   
  train_labels <- data[train_indices, 1]  
  test_labels <- data[test_indices, 1]    
  

  predicted_test_labels <- knn(train = train_data[, -1], test = test_data[, -1], cl = train_labels, k = 5)
  predicted_train_labels <- knn(train = train_data[, -1], test = train_data[, -1], cl = train_labels, k = 5)
  
  accuracy[i] <- sum(predicted_test_labels == test_labels) / length(test_labels)
  train_error[i] <- sum(predicted_train_labels != train_labels) / length(train_labels)
  test_error[i] <- sum(predicted_test_labels != test_labels) / length(test_labels)
}

mean_accuracy <- mean(accuracy)
mean_train_error <- mean(train_error)
mean_test_error <- mean(test_error)

print(paste("Mean Accuracy:", mean_accuracy))
print(paste("Mean Train Error:", mean_train_error))
print(paste("Mean Test Error:", mean_test_error))
```


```{r,message=FALSE,warning=FALSE}
library(e1071)
library(ggplot2)
data$diagnosis <- as.factor(data$diagnosis)
set.seed(123) 
train_indices <- sample(1:nrow(data), 0.7 * nrow(data), replace = FALSE)
train_data <- data[train_indices,]
test_data <- data[-train_indices,]
#radial as the kernel function
svm_model <- svm(diagnosis ~ ., data = train_data, kernel = "radial", cost = 10, scale = FALSE)
predictions <- predict(svm_model, test_data)
accuracy <- sum(predictions == test_data$Diagnosis) / nrow(test_data)
print(paste("Radial Accuracy:", accuracy))
table(predictions, test_data$diagnosis)
#linear as the kernel function (we choose this)
svm_model <- svm(diagnosis ~ ., data = train_data, kernel = "linear", cost = 1, probability = TRUE)
predictions <- predict(svm_model, test_data)
accuracy <- sum(predictions == test_data$Diagnosis) / nrow(test_data)
print(paste("Linear Accuracy:", accuracy))
table(predictions, test_data$diagnosis)

#predict probability
predictions <- predict(svm_model, test_data, probability = TRUE)

svm_probabilities <- attr(predictions, "probabilities")

```
```{r, message = FALSE, warning = FALSE}
# 10-fold cross validation

accuracy <- numeric(10)
train_error <- numeric(10)
test_error <- numeric(10)

for(i in 1:10) {
  test_indices <- which(folds == i, arr.ind = TRUE)
  train_indices <- which(folds != i, arr.ind = TRUE)
  
  train_data <- data[train_indices,]
  test_data <- data[test_indices,]
  
  svm_model <- svm(diagnosis ~ ., data = train_data, kernel = "linear", cost = 1, scale = FALSE)

  predictions_train <- predict(svm_model, train_data)
  predictions_test <- predict(svm_model, test_data)
  
  accuracy[i] <- sum(predictions_test == test_data$Diagnosis) / nrow(test_data)
  train_error[i] <- 1 - sum(predictions_train == train_data$Diagnosis) / nrow(train_data)
  test_error[i] <- 1 - accuracy[i]
}

mean_accuracy <- mean(accuracy)
mean_train_error <- mean(train_error)
mean_test_error <- mean(test_error)
print(paste("Average Accuracy: ", mean_accuracy))
print(paste("Average Train Error: ", mean_train_error))
print(paste("Average Test Error: ", mean_test_error))
```
```{r,message=FALSE,warning=FALSE}
# plotting
pca_results <- prcomp(data[, -c(1,2)], scale. = TRUE)
data_pca <- data.frame(pca_results$x[, 1:2])
colnames(data_pca) <- c("PC1", "PC2")
data_pca$diagnosis <- data$diagnosis

# Use PCA to reduce to 2 dimensions 
svm_model <- svm(diagnosis ~ ., data = data_pca, kernel = "linear")
predictions <- predict(svm_model, data_pca)
#Plot SVM
accuracy <- sum(predictions == data_pca$diagnosis) / nrow(data_pca)
print(paste("PCA SVM Accuracy:", accuracy))
sv <- data_pca[svm_model$index, ]
xrange <- range(data_pca$PC1)
yrange <- range(data_pca$PC2)
grid <- expand.grid(PC1 = seq(from = xrange[1], to = xrange[2], length.out = 200),
                    PC2 = seq(from = yrange[1], to = yrange[2], length.out = 200))
prediction_results <- predict(svm_model, newdata = grid, decision.values = TRUE)
grid$DecisionValue <- attributes(prediction_results)$decision
plot <- ggplot(data_pca, aes(x = PC1, y = PC2)) +
  geom_point(aes(color = diagnosis), alpha = 0.5) +
  geom_point(data = sv, aes(shape = "Support Vectors"), size = 4, stroke = 2) +
  geom_contour(data = grid, aes(z = DecisionValue), breaks = 0, color = "black") +
  scale_color_manual(values = c("red", "blue")) +
  labs(title = "SVM with PCA Reduction and Decision Line", x = "Principal Component 1", y = "Principal Component 2")
print(plot)


```